{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST training notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import snntorch as snn \n",
    "from snntorch import spikegen\n",
    "import snntorch.spikeplot as splt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0,), (1,))\n",
    "    ]\n",
    ")\n",
    "datapath = \"../data\"\n",
    "train_dataset = MNIST(datapath, train=True, transform=transform, download=False)  # Change download=True first time\n",
    "test_dataset = MNIST(datapath, train=False, transform=transform, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataloaders\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.train_data.shape, test_dataset.train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_INPUTS: 784, NUM_HIDDENS: 1000, NUM_OUTPUTS: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda3/envs/ini/lib/python3.11/site-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "TAU = 5e-3\n",
    "DT = 1  # ms\n",
    "BETA = 0.9\n",
    "THRESHOLD = 1.0\n",
    "NUM_STEPS = 25\n",
    "\n",
    "NUM_INPUTS = len(train_dataset.train_data[0].flatten())\n",
    "NUM_HIDDENS = 1000  # Design choice\n",
    "NUM_OUTPUTS = 10  # Number of output classes\n",
    "print(f\"NUM_INPUTS: {NUM_INPUTS}, NUM_HIDDENS: {NUM_HIDDENS}, NUM_OUTPUTS: {NUM_OUTPUTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"Simple 3-layer, feed-forward SNN\"\"\"\n",
    "\n",
    "    def __init__(self, num_inputs: int, num_hiddens: int, num_outputs: int, \n",
    "                 tau: float, dt, beta: float, threshold: float, num_steps: int):\n",
    "        \"\"\"Initialise hyperparameters and architecture\"\"\"\n",
    "        super().__init__()  # Get good stuff from pytorch.nn.Module\n",
    "\n",
    "        # Hyperparams\n",
    "        self.tau = tau\n",
    "        self.dt = dt\n",
    "        self.beta = beta\n",
    "        self.threshold = threshold\n",
    "        self.num_steps = num_steps  # No. simulation steps for 1 example\n",
    "\n",
    "        # Architecture\n",
    "        self.fc1 = nn.Linear(in_features=num_inputs, out_features=num_hiddens)\n",
    "        self.lif1 = snn.Leaky(beta=beta, threshold=threshold)\n",
    "        self.fc2 = nn.Linear(in_features=num_hiddens, out_features=num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta, threshold=threshold)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialise membrane potential tensors\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Create arrays to store spikes over time\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        # Iterate over all timesteps for 1 example\n",
    "        for step in range(self.num_steps):\n",
    "            # TODO: x is not spikes, but this generates effectively I = WX for input to LIF potential\n",
    "            # Also same x is fed into network at each time, should be probabilistic spike over time instead, x[step] (index in time)\n",
    "            cur1 = self.fc1(x)  \n",
    "            spk1, mem1 = self.lif1(cur1)\n",
    "            cur2 = self.fc1(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2)\n",
    "\n",
    "            spk2_rec.append(spk2)  # Store spike outputs & membrane voltage\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec)\n",
    "    \n",
    "net = Net(num_inputs=NUM_INPUTS, num_hiddens=NUM_HIDDENS, num_outputs=NUM_OUTPUTS,\n",
    "          tau=TAU, dt=DT, beta=BETA, threshold=THRESHOLD, num_steps=NUM_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `fc1` applies a linear transformation to all input pixels from the MNIST dataset;\n",
    "* `lif1` integrates the weighted input over time, emitting a spike if the threshold condition is met;\n",
    "* `fc2` applies a linear transformation to the output spikes of `lif1`;\n",
    "* `lif2` is another spiking neuron layer, integrating the weighted spikes over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
